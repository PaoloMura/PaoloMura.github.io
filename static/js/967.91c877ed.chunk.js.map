{"version":3,"file":"static/js/967.91c877ed.chunk.js","mappings":"yIAgDA,UA9CA,WACI,OACI,iCACI,4YAKA,oGAGA,2BACI,8CACA,+FACA,4EACA,mFACA,+EAEJ,SAAC,IAAK,CAACA,OAAK,EAACC,IAAI,yCACjB,+DAGA,2BACI,uEACA,+EACA,iGACA,iFACA,qIACA,wHAEJ,qfAMA,SAAC,IAAK,CAACD,OAAK,EAACC,IAAI,sCACjB,8NAOZ,C","sources":["Projects/RenderFarm.js"],"sourcesContent":["import { Image } from 'react-bootstrap';\n\nfunction RenderFarm() {\n    return (\n        <>\n            <p>\n                This project was the coursework for my fourth year Cloud Computing and Big Data unit.\n                The challenge was to create a cloud application that could complete an embarassingly parallelisable task and we were given access to an AWS learner lab.\n                I chose to create a render farm, which takes in a Blender project file and renders the animation into a finished MP4 video file.\n            </p>\n            <p>\n                The application itself is constructed using the following AWS services:\n            </p>\n            <ul>\n                <li>Lambda functions</li>\n                <li>S3 buckets (for storing the input, output and intermediate files)</li>\n                <li>DynamoDB (for storing a table of job statuses)</li>\n                <li>EKS cluster (for carrying out the processing of jobs)</li>\n                <li>SQS queue (for submitting jobs to the cluster)</li>\n            </ul>\n            <Image fluid src='/images/render-farm/RenderFarm.jpeg' />\n            <p>\n                The overall process is as follows:\n            </p>\n            <ol>\n                <li>The client stores the Blender file in S3.</li>\n                <li>The client submits a rendering job to the server.</li>\n                <li>The server splits the job into batches (e.g. frames 1-3, 4-6, ...).</li>\n                <li>The server sends the batches to the worker cluster.</li>\n                <li>Each worker node processes a batch, rendering their assigned range of frames and storing results to S3.</li>\n                <li>Once all batches are done, one worker node sequences the frames into a single MP4 file.</li>\n            </ol>\n            <p>\n                On top of the obvious speedup that comes with parallelisation, the application also included scalability and fault tolerance.\n                I used a Kubernetes horizontal pod autoscaler to increase the number of pods in the cluster when % CPU usage increased above a threshold.\n                EKS is itself fault tolerant and I set the SQS queue to make job messages visible again after a timeout from when they were consumed.\n                This allowed jobs to be rescheduled if a node failed to process its batch.\n            </p>\n            <Image fluid src='/images/render-farm/Scaling.jpeg' />\n            <p>\n                The red line represents % CPU usage.\n                The blue line is the number of pods.\n                The dashed green line is the threshold % CPU usage that determines whether to increase or decrease the number of pods.\n            </p>\n        </>\n    );\n}\n\nexport default RenderFarm;"],"names":["fluid","src"],"sourceRoot":""}