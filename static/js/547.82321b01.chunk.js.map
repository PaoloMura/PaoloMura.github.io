{"version":3,"file":"static/js/547.82321b01.chunk.js","mappings":"yIAyCA,UAvCA,WACI,OACI,iCACI,+PAIA,kOAIA,SAAC,IAAK,CAACA,OAAK,EAACC,IAAI,mDACjB,wPAIA,SAAC,IAAK,CAACD,OAAK,EAACC,IAAI,uDACjB,+dAMA,SAAC,IAAK,CAACD,OAAK,EAACC,IAAI,oDACjB,obAMA,SAAC,IAAK,CAACD,OAAK,EAACC,IAAI,8CACjB,2LAGA,SAAC,IAAK,CAACD,OAAK,EAACC,IAAI,8CAG7B,C","sources":["Projects/RenderingEngine.js"],"sourcesContent":["import { Image } from 'react-bootstrap';\n\nfunction RenderingEngine() {\n    return (\n        <>\n            <p>\n                This project was the coursework for my third year Computer Graphics unit.\n                The task was to build a rendering engine from the ground up using C++ and strictly limited to SDL's basic functionality (drawing a pixel onto a window).\n            </p>\n            <p>\n                My solution was able to parse the OBJ and MTL files that contained information on the 3D model's vertices, faces and colours.\n                The OBJ file specified where in 3D space each vertex of the object was.\n            </p>\n            <Image fluid src='/images/rendering-engine/PointProjection.jpeg' />\n            <p>\n                Consider a virtual camera looking towards the object with a virtual 2D screen in between them.\n                In my first rasterised approach, I cast 'rays' from each vertex to the camera to find the intersetion point with the screen.\n            </p>\n            <Image fluid src='/images/rendering-engine/RasterisedTriangles.jpeg' />\n            <p>\n                From here, my engine drew lines between the vertices and then filled the triangles in that made up each face.\n                At this point I also added functionality for camera movement.\n                This used matrix multiplication to change the direction the camera was positioned and oriented with respect to the 3D model.\n                Another feature was texture mapping, which takes in an image file and maps pixels from the image to the triangle rather than just using one solid colour.\n            </p>\n            <Image fluid src='/images/rendering-engine/RasterisedRender.jpeg' />\n            <p>\n                The second approach I used was ray-tracing.\n                Unlike before, this casts rays from the camera into the scene, checking to see if it intersects with a point on the object.\n                If so, it then casts a ray from that point to a light source.\n                Various factors such as the proximity to the light source and angle of incidence of the light ray affect the brightness of the corresponding pixel that gets drawn on the screen.\n            </p>\n            <Image fluid src='/images/rendering-engine/RayTracing.jpeg' />\n            <p>\n                The use of ray tracing allowed me to implement logic for more complex rendering such as mirrored surfaces and Gouraud and Phong shading for spherical objects.\n            </p>\n            <Image fluid src='/images/rendering-engine/RayTraced.jpeg' />\n        </>\n    );\n}\n\nexport default RenderingEngine;"],"names":["fluid","src"],"sourceRoot":""}